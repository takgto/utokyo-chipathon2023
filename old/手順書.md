# yolov3の学習
## 0. Darknetフォルダを自分のGoogleDriveにアップロード
予め配布されたURLもしくはPC内にあるフォルダからアップロードしてください。

## 1. colabに接続
google colaboratoryに行き、新しいnotebookを作成してください。
上のランタイム→ランタイムのタイプを変更→ハードウェアアクセラレータをGPUにして保存してください。

## 2. Notebookで以下を実行
```python
import os
from google.colab import drive
drive.mount('/content/drive')
```
```bash
%cd '/content/drive/MyDrive/darknet
!make # これでコンパイルしています
!chmod +x ./darknet # 実行権限を与えています。
```
```bash
# 実行
!./darknet detector train work/obj.data work/yolov3-608.cfg darknet53.conv.74 -dont_show
```

3時間かかるらしいです。

## 3. 学習結果の確認
`/darknet/cahrt.png` に学習結果が表示されているので確認してください。
あるいは、自分で以下のように実行することも出来ます（入力が416x416より大きい場合などはこちらで行います。）

```bash
!./darknet detector map work/obj.data work/yolov3-608.cfg work/backup/yolov3-608_1000.weights -dont_show -ext_output < work/val.txt
```

# PCでモデルを量子化し、コンパイルする
## 1. 学習結果を保存する
`darknet/work/backup/(config_name)_best.weights`をGoogleDriveから手元にダウンロードします。
## 2. ダウンロードした結果をWSL上に持ってくる
```bash
cp /path/to/yolov4-608_best.weights ~/Vitis-AI/yolov3-dlab/work/backup
```
## 3. WSLでDocker Containerを立ち上げる
### 1. Docker Desktopをデスクトップアイコンをクリックして立ち上げる
### 2. 以下でDocker Imageをロードする
```bash
docker load -i vitis-ai-cpu.tar
```
これが終わると以下のコマンドで、xilinx/vitis-ai-cpu:latestというのが見えるはずです。
```bash
docker image ls -a
```
### 3. Dockerコンテナの立ち上げ
```bash
cd ~/Vitis-AI
./docker_run.sh xilinx/vitis-ai-cpu:latest
```

### 4. Conda環境を立ち上げる
Docker内で以下を実行する

```
conda activate vitis-ai-tensorflow2
pip install dm-tree~=0.1.1
pip install tensorflow==2.8.0
cd /workspace/src/Vitis-AI-Quantizer/vai_q_tensorflow2.x/pkgs
pip install --force-reinstall *.whl
pip install keras_applications 
```
pkgsがない場合は

```bash
cd ~/Vitis-AI/src/Vitis-AI-Quantizer/vai_q_tensorflow2.x
export SRC_DIR=$(pwd)
cd /workspace/src/Vitis-AI-Quantizer/vai_q_tensorflow2.x 
sh vai_q_tensorflow2_cpu_feedstock/build.sh 
```

## 4. モデルのKerasへの変換および量子化

```bash
cd /workspace/yolov3-dlab/scripts_tf2
./convert_yolov3.sh
```

```bash
cd /workspace/yolov-dlab/keras_model
ls # モデルが見えるはず
```

```bash
cd /workspace/yolov3-dlab/scripts_tf2
python my_quantizer.py -i
```

## 5. モデルのコンパイル
```bash
cd /workspace/yolov3-dlab/scripts_tf2
./compile_yolov3.sh
```

# FPGAで実行する
## 1. MobaXtermでSerial接続
MobaXtermを立ち上げSessionからSerialで接続する。

COM4もしくはCOM7など、2つ見えているうちの小さいほうの番号のポートを選び、Speedは115200bps。
## 2. IPアドレスなどを設定する
```bash
source ./init260.sh
# dpuの最適化をする
./dpu_sw_optimize/zynqmp/zynqmp_dpu_optimize.sh
```
## 3. 推論準備
```bash
cd /usr/share/vitis_ai_library/models
mkdir dpu_yolov3-608
```
PCから今作ったディレクトリに`xmodel`, `md5sum.txt`, `meta.json` の3つを転送しましょう。順調に作業が進んでいれば`/workspace/yolov3-dlab/yolov3_quantized2`に存在しているはずです。

FPGA上で、prototxtをコピーします
```bash
cd ./dpu_yolov3-608
cp ../yolov3_coco_416_tf2/yolov3_coco_416_tf2.prototxt dpu_yolov3-608.prototxt
```

ここで、ファイルを編集するためにVSCodeでSSHをし、FPGAに接続しましょう。私はVim使いになるんだ！という人は以下の面倒な手順は踏まなくても大丈夫です。

VSCodeの左下の青い矢印をクリックして、以下のような画面を出します。

![image](https://github.com/yutyan0119/utokyo-chipathon2023/assets/78634880/acd1aaa8-7504-4b53-bfc2-11a7925e308b)

ホストに接続する、を押し、1番下のSSHホストを構成する...を押します。SSH構成ファイルは1番上のものでいいです。設定ファイルに以下のように追加します。

```bash
Host kv260
  HostName 192.168.1.100
  User root
  X11Forwarding yes
```
追加したらさっきと同じように、左下の青色矢印からホストに接続するを押し、kv260を選びます。OSの選択が出てきたらLinuxを、パスワードを要求されたらパスワードを入れてください。

VSCodeの下側からシェルを出し、`code /usr/share/vitis_ai_library/models/dpu_yolov3-608`と入力し、新しいフォルダでVSCodeを開きます。

あとは`dpu_yolov3-608.txt`の`num_classes: 80`を`num_classes: 3`に変更してください。

###注意
ディレクトリ名とファイル名(拡張子なし)は一致させてください。

## 4. 画像推論
モデルをビルドします。FPGA上で
```
cd ~/Vitis-AI/examples/Vitis-AI-Library/samples/yolov3
./build.sh
```
を実行します。結構時間がかかるので、焦らず待ちましょう。

次に、FPGA（に接続したMobaXTermやVSCode）で
```bash
xmutil listapps
xmutil unloadapp
xmutil loadapp kv260-benchmark-b4096
```
を実行して、ロードしてください。

以下で、画像に対して推論を行います。
```bash
cd ~/Vitis-AI/examples/Vitis-AI-Library/samples/yolov3
cp ~/data/COCO_mydata/val2017/000000020904.jpg .
./test_jpeg_yolov3 dpu_yolov3-608 000000020904.jpg
```

この画像を見たい場合はVSCodeで開くことで見えます。

## 5. 画像推論

```bash
cd ~/Vitis-AI/examples/VART/yolov3
ln –s /usr/share/vitis_ai_library/models/dpu_yolov3-608/dpu_yolov3-608.xmodel dpu_yolov3-608.xmodel
./build.sh
./yolov3 dpu_yolov3-608.xmodel ./video/adas.webm
```
もしVSCodeで動画が見えない場合はMobaXtermで実行してください。

## 6. 精度検証
以下でmAPを計算します。
```bash
cd ~/Vitis-AI/examples/Vitis-AI-Library/samples/yolov3
./test_file_yolov3 dpu_yolov3-608 val2017.txt
cd mAP
python3 main.py -na
```